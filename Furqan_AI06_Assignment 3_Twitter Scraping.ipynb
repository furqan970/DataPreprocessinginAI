{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b19ca67",
   "metadata": {},
   "source": [
    "# Twitter Scraping using SNS Scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd09a44",
   "metadata": {},
   "source": [
    "# Installing and importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5704a60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/JustAnotherArchivist/snscrape.git\n",
      "  Cloning https://github.com/JustAnotherArchivist/snscrape.git to c:\\users\\furqan970\\appdata\\local\\temp\\pip-req-build-e_7dbvk3\n",
      "  Resolved https://github.com/JustAnotherArchivist/snscrape.git to commit c3b216c3cb8593513a018eb3ec4fd6f18d3aba5b\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\furqan970\\anaconda3\\lib\\site-packages (from snscrape==0.6.2.20230321.dev39+gc3b216c) (2.28.1)\n",
      "Requirement already satisfied: lxml in c:\\users\\furqan970\\anaconda3\\lib\\site-packages (from snscrape==0.6.2.20230321.dev39+gc3b216c) (4.9.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\furqan970\\anaconda3\\lib\\site-packages (from snscrape==0.6.2.20230321.dev39+gc3b216c) (4.11.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\furqan970\\anaconda3\\lib\\site-packages (from snscrape==0.6.2.20230321.dev39+gc3b216c) (3.6.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\furqan970\\anaconda3\\lib\\site-packages (from beautifulsoup4->snscrape==0.6.2.20230321.dev39+gc3b216c) (2.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\furqan970\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape==0.6.2.20230321.dev39+gc3b216c) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\furqan970\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape==0.6.2.20230321.dev39+gc3b216c) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\furqan970\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape==0.6.2.20230321.dev39+gc3b216c) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\furqan970\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape==0.6.2.20230321.dev39+gc3b216c) (2022.9.14)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\furqan970\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape==0.6.2.20230321.dev39+gc3b216c) (1.7.1)\n",
      "Building wheels for collected packages: snscrape\n",
      "  Building wheel for snscrape (pyproject.toml): started\n",
      "  Building wheel for snscrape (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for snscrape: filename=snscrape-0.6.2.20230321.dev39+gc3b216c-py3-none-any.whl size=74289 sha256=271225fd9aa8a788223eb2dbeb4949fc8660e40b378037d93656b084d752c823\n",
      "  Stored in directory: C:\\Users\\Furqan970\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-q86biz0q\\wheels\\1a\\ba\\e2\\39fa3a11802c4a622f2efc8be3f5ff854481051d0b4c95c1fd\n",
      "Successfully built snscrape\n",
      "Installing collected packages: snscrape\n",
      "  Attempting uninstall: snscrape\n",
      "    Found existing installation: snscrape 0.6.2.20230321.dev32+gb76f485\n",
      "    Uninstalling snscrape-0.6.2.20230321.dev32+gb76f485:\n",
      "      Successfully uninstalled snscrape-0.6.2.20230321.dev32+gb76f485\n",
      "Successfully installed snscrape-0.6.2.20230321.dev39+gc3b216c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/JustAnotherArchivist/snscrape.git 'C:\\Users\\Furqan970\\AppData\\Local\\Temp\\pip-req-build-e_7dbvk3'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\furqan970\\anaconda3\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\furqan970\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\furqan970\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\furqan970\\anaconda3\\lib\\site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\furqan970\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Run the pip install command below if you don't already have the library\n",
    "!pip install git+https://github.com/JustAnotherArchivist/snscrape.git\n",
    "\n",
    "# Run the below command if you don't already have Pandas\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77bb8f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341806fc",
   "metadata": {
    "id": "V2bBVOAIEMOJ"
   },
   "source": [
    "# Query by Username\n",
    "The code below will scrape for 100 tweets by a username then provide a CSV file with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "682a061f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t6HpbyaGEMOJ",
    "outputId": "fb4fd5d7-3f58-4ad6-e7b9-7d1215755ca8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Furqan970\\AppData\\Local\\Temp\\ipykernel_13848\\926890194.py:11: DeprecatedFeatureWarning: content is deprecated, use rawContent instead\n",
      "  tweets_list1.append([tweet.date, tweet.id, tweet.content, tweet.user.username])\n"
     ]
    }
   ],
   "source": [
    "# Setting variables to be used below\n",
    "maxTweets = 100\n",
    "\n",
    "# Creating list to append tweet data to\n",
    "tweets_list1 = []\n",
    "\n",
    "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('from:elonmusk').get_items()):\n",
    "    if i>maxTweets:\n",
    "        break\n",
    "    tweets_list1.append([tweet.date, tweet.id, tweet.content, tweet.user.username])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac0a129c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "LIEL_ql7EMOJ",
    "outputId": "3b9611c3-f575-4e6a-a98d-fc5654fb26e6",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-11 16:44:52+00:00</td>\n",
       "      <td>1667935943708356608</td>\n",
       "      <td>@StephenKing There is also equal treatment bef...</td>\n",
       "      <td>elonmusk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-11 06:36:36+00:00</td>\n",
       "      <td>1667782870423724033</td>\n",
       "      <td>@RichardHanania But if you discriminate agains...</td>\n",
       "      <td>elonmusk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-06-11 06:33:00+00:00</td>\n",
       "      <td>1667781964336709632</td>\n",
       "      <td>@andrewdoyle_com UK now understands. America w...</td>\n",
       "      <td>elonmusk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-06-11 06:10:16+00:00</td>\n",
       "      <td>1667776242081484801</td>\n",
       "      <td>@teslaownersSV @WR4NYGov Yeah</td>\n",
       "      <td>elonmusk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-06-11 05:24:50+00:00</td>\n",
       "      <td>1667764809457098752</td>\n",
       "      <td>@LibertyCappy It is insane</td>\n",
       "      <td>elonmusk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Datetime             Tweet Id  \\\n",
       "0 2023-06-11 16:44:52+00:00  1667935943708356608   \n",
       "1 2023-06-11 06:36:36+00:00  1667782870423724033   \n",
       "2 2023-06-11 06:33:00+00:00  1667781964336709632   \n",
       "3 2023-06-11 06:10:16+00:00  1667776242081484801   \n",
       "4 2023-06-11 05:24:50+00:00  1667764809457098752   \n",
       "\n",
       "                                                Text  Username  \n",
       "0  @StephenKing There is also equal treatment bef...  elonmusk  \n",
       "1  @RichardHanania But if you discriminate agains...  elonmusk  \n",
       "2  @andrewdoyle_com UK now understands. America w...  elonmusk  \n",
       "3                      @teslaownersSV @WR4NYGov Yeah  elonmusk  \n",
       "4                         @LibertyCappy It is insane  elonmusk  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe from the tweets list above\n",
    "tweets_df1 = pd.DataFrame(tweets_list1, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])\n",
    "\n",
    "# Display first 5 entries from dataframe\n",
    "tweets_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b17caf0",
   "metadata": {
    "id": "EQLNMl8dEMOK"
   },
   "outputs": [],
   "source": [
    "# Export dataframe into a CSV\n",
    "tweets_df1.to_csv('user-tweets.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c79833",
   "metadata": {
    "id": "StWy4TD3EMOK"
   },
   "source": [
    "# Query by Text Search\n",
    "The code below will scrape for 500 tweets between June 1st, 2022 and June 11th, 2023, by a text search then provide a CSV file with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed299572",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OZCzOEzvEMOK",
    "outputId": "74d26e61-48ff-46e3-953e-c9892eef13af"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Furqan970\\AppData\\Local\\Temp\\ipykernel_13848\\101611164.py:11: DeprecatedFeatureWarning: content is deprecated, use rawContent instead\n",
      "  tweets_list2.append([tweet.date, tweet.id, tweet.content, tweet.user.username])\n"
     ]
    }
   ],
   "source": [
    "# Setting variables to be used below\n",
    "maxTweets = 500\n",
    "\n",
    "# Creating list to append tweet data to\n",
    "tweets_list2 = []\n",
    "\n",
    "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('cat since:2022-06-01 until:2023-06-11').get_items()):\n",
    "    if i>maxTweets:\n",
    "        break\n",
    "    tweets_list2.append([tweet.date, tweet.id, tweet.content, tweet.user.username])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aefcf573",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "r9naOEx7EMOK",
    "outputId": "cafe310c-fea2-404b-d9cf-37fa22131a1d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-10 23:59:59+00:00</td>\n",
       "      <td>1667683058169024512</td>\n",
       "      <td>i miss sansa and bran and rickon actually wait</td>\n",
       "      <td>helaenapilled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-10 23:59:59+00:00</td>\n",
       "      <td>1667683056822411266</td>\n",
       "      <td>I didn't get a new paper bag nest today, but I...</td>\n",
       "      <td>HarleyQuinnCat3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-06-10 23:59:59+00:00</td>\n",
       "      <td>1667683056222863361</td>\n",
       "      <td>accessory - misc likes\\n- dr. pepper\\n- cats\\n...</td>\n",
       "      <td>d4remurdock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-06-10 23:59:58+00:00</td>\n",
       "      <td>1667683054217986048</td>\n",
       "      <td>おはようございます🐱\\n今日も1日\\nよろしくお願いします🙏\\n\\n #猫 #キジトラ  #...</td>\n",
       "      <td>kmjmyk908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-06-10 23:59:58+00:00</td>\n",
       "      <td>1667683052565446656</td>\n",
       "      <td>小林っ</td>\n",
       "      <td>SvdScar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Datetime             Tweet Id  \\\n",
       "0 2023-06-10 23:59:59+00:00  1667683058169024512   \n",
       "1 2023-06-10 23:59:59+00:00  1667683056822411266   \n",
       "2 2023-06-10 23:59:59+00:00  1667683056222863361   \n",
       "3 2023-06-10 23:59:58+00:00  1667683054217986048   \n",
       "4 2023-06-10 23:59:58+00:00  1667683052565446656   \n",
       "\n",
       "                                                Text         Username  \n",
       "0     i miss sansa and bran and rickon actually wait    helaenapilled  \n",
       "1  I didn't get a new paper bag nest today, but I...  HarleyQuinnCat3  \n",
       "2  accessory - misc likes\\n- dr. pepper\\n- cats\\n...      d4remurdock  \n",
       "3  おはようございます🐱\\n今日も1日\\nよろしくお願いします🙏\\n\\n #猫 #キジトラ  #...        kmjmyk908  \n",
       "4                                                小林っ          SvdScar  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe from the tweets list above\n",
    "tweets_df2 = pd.DataFrame(tweets_list2, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])\n",
    "\n",
    "# Display first 5 entries from dataframe\n",
    "tweets_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc761f82",
   "metadata": {
    "id": "IRais8APEMOL"
   },
   "outputs": [],
   "source": [
    "# Export dataframe into a CSV\n",
    "tweets_df2.to_csv('text-query-tweets.csv', sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
